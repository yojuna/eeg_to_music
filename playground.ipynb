{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [1, 2, 3]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat(4, 2,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_eeg_signal= np.arange(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_eeg_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_eeg = np.pad(pos_eeg_signal, (0, 5), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = t.LongTensor(padded_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mask = pos.ne(0).type(t.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pos.eq(0).unsqueeze(1).repeat(1, input_1d.size(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [False],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1d.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1d = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1d = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                        [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]], dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1d = input_1d.unsqueeze(1)\n",
    "input_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn1d_1: \n",
      "\n",
      "torch.Size([1, 5, 8]) \n",
      "\n",
      "tensor([[[  0.9763,   1.3095,   1.6427,   1.9759,   2.3092,   2.6424,   2.9756,\n",
      "            3.3089],\n",
      "         [ -1.9052,  -2.8829,  -3.8605,  -4.8382,  -5.8158,  -6.7934,  -7.7711,\n",
      "           -8.7487],\n",
      "         [ -2.6257,  -3.6805,  -4.7354,  -5.7902,  -6.8451,  -7.8999,  -8.9548,\n",
      "          -10.0096],\n",
      "         [  0.4231,   0.5153,   0.6075,   0.6997,   0.7919,   0.8841,   0.9763,\n",
      "            1.0685],\n",
      "         [ -2.1019,  -2.6746,  -3.2473,  -3.8200,  -4.3927,  -4.9655,  -5.5382,\n",
      "           -6.1109]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "cnn1d_1 = nn.Conv1d(in_channels=8, out_channels=5, kernel_size=3, stride=1)\n",
    "print(\"cnn1d_1: \\n\")\n",
    "print(cnn1d_1(input_1d).shape, \"\\n\")\n",
    "print(cnn1d_1(input_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(25, 156, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-53bf00b48171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "embed(input_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperparams as hp\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from text import text_to_sequence\n",
    "import collections\n",
    "from scipy import signal\n",
    "import torch as t\n",
    "import math\n",
    "from utils import stim_event_dict\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenMIIRDataset_(Dataset):\n",
    "    \"\"\"Process the prepared OpenMIIR dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, loaded_npz, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            npz_file (string): Path to the .npz file with saved eeg signal data.\n",
    "            root_dir (string): Directory with all the wavs.\n",
    "        \"\"\"\n",
    "#         self.loaded_arrays = np.nditer(np.load(npz_file))\n",
    "        self.loaded_arrays = loaded_npz\n",
    "        self.array_indexes = self.loaded_arrays.files\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def load_wav(self, filename):\n",
    "        return librosa.load(filename, sr=hp.sample_rate)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.array_indexes)\n",
    "\n",
    "    def get_wav_path(self, array_index):\n",
    "        exp_id = array_index.split('_')[0]\n",
    "        print('here?')\n",
    "        stimulus_id = get_stimulus_id(int(exp_id))\n",
    "        wav_filename = stim_event_dict[stimulus_id]\n",
    "        wav_filepath = os.path.join(self.root_dir, wav_filename)\n",
    "        return wav_filepath\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        print('class mein')\n",
    "        wav_name = self.get_wav_path(self.array_indexes[idx])\n",
    "        print('wav_name', wav_name)\n",
    "        eeg_array = self.loaded_arrays[self.array_indexes[idx]]\n",
    "\n",
    "        mel = np.load(wav_name[:-4] + '.pt.npy')\n",
    "        mel_input = np.concatenate([np.zeros([1, hp.num_mels], np.float32), mel[:-1,:]], axis=0)\n",
    "        eeg_signal_dimensions = eeg_array.shape\n",
    "        eeg_signal_length = eeg_array.shape[1]\n",
    "        # text_length = len(text)\n",
    "        pos_eeg_signal= np.arange(1, eeg_signal_length + 1)\n",
    "        pos_mel = np.arange(1, mel.shape[0] + 1)\n",
    "\n",
    "        sample = {\n",
    "            'eeg_array': eeg_array, \n",
    "            'mel': mel, \n",
    "            'mel_input':mel_input, \n",
    "            'pos_mel': pos_mel, \n",
    "            'pos_eeg_signal': pos_eeg_signal,\n",
    "            'eeg_signal_dimensions': eeg_signal_dimensions, \n",
    "            'eeg_signal_length': eeg_signal_length\n",
    "        }\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/archeron/dev/data/eeg_to_music_data'\n",
    "npz_filename = 'P01_extracted.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_():\n",
    "    print('at get_dataset()')\n",
    "    loaded_npz = np.load(os.path.join(data_path, npz_filename))\n",
    "    print(loaded_npz.files[0])\n",
    "    # return LJDatasets(os.path.join(hp.data_path,'metadata.csv'), os.path.join(hp.data_path,'wavs'))\n",
    "    return OpenMIIRDataset_(loaded_npz, os.path.join(data_path, 'processed_wavs'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_transformer_(batch):\n",
    "\n",
    "    # Puts each data field into a tensor with outer dimension batch size\n",
    "    if isinstance(batch[0], collections.Mapping):\n",
    "\n",
    "        eeg_array = [d['eeg_array'] for d in batch]\n",
    "        mel = [d['mel'] for d in batch]\n",
    "        mel_input = [d['mel_input'] for d in batch]\n",
    "        pos_mel = [d['pos_mel'] for d in batch]\n",
    "        pos_eeg_signal= [d['pos_eeg_signal'] for d in batch]\n",
    "        eeg_signal_length = [d['eeg_signal_length'] for d in batch]\n",
    "        \n",
    "        eeg_array = [i for i,_ in sorted(zip(eeg_array, eeg_signal_length), key=lambda x: x[1], reverse=True)]\n",
    "        mel = [i for i, _ in sorted(zip(mel, eeg_signal_length), key=lambda x: x[1], reverse=True)]\n",
    "        mel_input = [i for i, _ in sorted(zip(mel_input, eeg_signal_length), key=lambda x: x[1], reverse=True)]\n",
    "        pos_eeg_signal = [i for i, _ in sorted(zip(pos_eeg_signal, eeg_signal_length), key=lambda x: x[1], reverse=True)]\n",
    "        pos_mel = [i for i, _ in sorted(zip(pos_mel, eeg_signal_length), key=lambda x: x[1], reverse=True)]\n",
    "        eeg_signal_length = sorted(eeg_signal_length, reverse=True)\n",
    "        # PAD sequences with largest length of the batch\n",
    "        eeg_array = _prepare_eeg_data(eeg_array)\n",
    "        mel = _pad_mel(mel)\n",
    "        mel_input = _pad_mel(mel_input)\n",
    "        pos_mel = _prepare_data(pos_mel).astype(np.int32)\n",
    "        pos_eeg_signal = _prepare_data(pos_eeg_signal).astype(np.int32)\n",
    "\n",
    "\n",
    "        return t.FloatTensor(eeg_array), t.FloatTensor(mel), t.FloatTensor(mel_input), t.LongTensor(pos_eeg_signal), t.LongTensor(pos_mel), t.LongTensor(eeg_signal_length)\n",
    "\n",
    "    raise TypeError((\"batch must contain tensors, numbers, dicts or lists; found {}\"\n",
    "                     .format(type(batch[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimulus_id(event_id):\n",
    "    if event_id < 1000:\n",
    "        return int(event_id / 10)\n",
    "    else:\n",
    "        return event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_eeg_data(input_array, length):\n",
    "    print('input_array shape: ', input_array.shape[1])\n",
    "    _pad = 0\n",
    "    return np.stack([np.pad(x, (0, length - input_array.shape[1]), mode='constant', constant_values=_pad) for x in input_array])\n",
    "\n",
    "def _pad_data(x, length):\n",
    "    _pad = 0\n",
    "    return np.pad(x, (0, length - x.shape[0]), mode='constant', constant_values=_pad)\n",
    "\n",
    "def _prepare_eeg_data(inputs):\n",
    "    max_len = max((x.shape[1] for x in inputs))\n",
    "    print('at _prepare_eeg_data()')\n",
    "    print('max length: ', max_len)\n",
    "    return np.stack([_pad_eeg_data(x, max_len) for x in inputs])\n",
    "\n",
    "def _prepare_data(inputs):\n",
    "    max_len = max((len(x) for x in inputs))\n",
    "    return np.stack([_pad_data(x, max_len) for x in inputs])\n",
    "\n",
    "def _pad_per_step(inputs):\n",
    "    timesteps = inputs.shape[-1]\n",
    "    return np.pad(inputs, [[0,0],[0,0],[0, hp.outputs_per_step - (timesteps % hp.outputs_per_step)]], mode='constant', constant_values=0.0)\n",
    "\n",
    "def get_param_size(model):\n",
    "    params = 0\n",
    "    for p in model.parameters():\n",
    "        tmp = 1\n",
    "        for x in p.size():\n",
    "            tmp *= x\n",
    "        params += tmp\n",
    "    return params\n",
    "\n",
    "def get_dataset():\n",
    "    print('at get_dataset()')\n",
    "    # return LJDatasets(os.path.join(hp.data_path,'metadata.csv'), os.path.join(hp.data_path,'wavs'))\n",
    "    return OpenMIIRDataset(os.path.join(hp.data_path, hp.npz_filename), os.path.join(hp.data_path, 'processed_wavs'))\n",
    "\n",
    "def get_post_dataset():\n",
    "    return PostDatasets(os.path.join(hp.data_path,'metadata.csv'), os.path.join(hp.data_path,'wavs'))\n",
    "\n",
    "def _pad_mel(inputs):\n",
    "    _pad = 0\n",
    "    def _pad_one(x, max_len):\n",
    "        mel_len = x.shape[0]\n",
    "        return np.pad(x, [[0,max_len - mel_len],[0,0]], mode='constant', constant_values=_pad)\n",
    "    max_len = max((x.shape[0] for x in inputs))\n",
    "    return np.stack([_pad_one(x, max_len) for x in inputs])\n",
    "\n",
    "def get_stimulus_id(event_id):\n",
    "    if event_id < 1000:\n",
    "        return int(event_id / 10)\n",
    "    else:\n",
    "        return event_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at get_dataset()\n",
      "121_520_8140_P01\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn_transformer_, drop_last=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S11_Chim_Chim_Cheree_no_lyrics_processed.wav\n",
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S11_Chim_Chim_Cheree_no_lyrics_processed.wav\n",
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S12_Take_Me_Out_To_The_Ballgame_no_lyrics_processed.wav\n",
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S11_Chim_Chim_Cheree_no_lyrics_processed.wav\n",
      "at _prepare_eeg_data()\n",
      "max length:  10789\n",
      "input_array shape:  10789\n",
      "input_array shape:  10787\n",
      "input_array shape:  7983\n",
      "input_array shape:  7616\n",
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S23_Star_Wars_Theme_processed.wav\n",
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S03_Jingle_Bells_lyrics_processed.wav\n",
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S04_Mary_Had_A_Little_Lamb_lyrics_processed.wav\n",
      "class mein\n",
      "here?\n",
      "wav_name /home/archeron/dev/data/eeg_to_music_data/processed_wavs/S23_Star_Wars_Theme_processed.wav\n",
      "at _prepare_eeg_data()\n",
      "max length:  10829\n",
      "input_array shape:  10829\n",
      "input_array shape:  9259\n",
      "input_array shape:  8935\n",
      "input_array shape:  41\n"
     ]
    }
   ],
   "source": [
    "eeg_array, mel, mel_input, pos_eeg_signal, pos_mel, _ = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0865e-03, -2.0887e-03, -2.0854e-03,  ..., -2.1194e-03,\n",
       "          -2.1182e-03, -2.1220e-03],\n",
       "         [-1.3048e-03, -1.3110e-03, -1.3085e-03,  ..., -1.3301e-03,\n",
       "          -1.3292e-03, -1.3355e-03],\n",
       "         [ 8.7062e-03,  8.7016e-03,  8.7020e-03,  ...,  8.6221e-03,\n",
       "           8.6237e-03,  8.6199e-03],\n",
       "         ...,\n",
       "         [-1.2700e-02, -1.2702e-02, -1.2703e-02,  ..., -1.2701e-02,\n",
       "          -1.2700e-02, -1.2700e-02],\n",
       "         [-5.8073e-03, -5.8065e-03, -5.8051e-03,  ..., -5.8142e-03,\n",
       "          -5.8136e-03, -5.8130e-03],\n",
       "         [ 0.0000e+00,  1.0000e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-6.3731e-04, -6.4203e-04, -6.4909e-04,  ..., -7.2584e-04,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.1725e-03, -1.1745e-03, -1.1830e-03,  ..., -1.2736e-03,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.8067e-03,  7.8036e-03,  7.7974e-03,  ...,  7.6998e-03,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [-1.0519e-02, -1.0527e-02, -1.0531e-02,  ..., -1.0495e-02,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.3525e-03, -5.3597e-03, -5.3620e-03,  ..., -5.3542e-03,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-6.3909e-04, -6.3691e-04, -6.4194e-04,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.2017e-03, -1.2020e-03, -1.2058e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.7435e-03,  7.7447e-03,  7.7411e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [-1.0364e-02, -1.0359e-02, -1.0365e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.2274e-03, -5.2247e-03, -5.2323e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.1300e+02,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.6631e-03, -1.6607e-03, -1.6631e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-1.7045e-03, -1.7017e-03, -1.7026e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 7.8962e-03,  7.8972e-03,  7.8948e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         ...,\n",
       "         [-1.2113e-02, -1.2114e-02, -1.2118e-02,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [-5.6234e-03, -5.6213e-03, -5.6247e-03,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  1.0000e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 69, 10789])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0865e-03, -2.0887e-03, -2.0854e-03,  ..., -2.1194e-03,\n",
       "         -2.1182e-03, -2.1220e-03],\n",
       "        [-1.3048e-03, -1.3110e-03, -1.3085e-03,  ..., -1.3301e-03,\n",
       "         -1.3292e-03, -1.3355e-03],\n",
       "        [ 8.7062e-03,  8.7016e-03,  8.7020e-03,  ...,  8.6221e-03,\n",
       "          8.6237e-03,  8.6199e-03],\n",
       "        ...,\n",
       "        [-1.2700e-02, -1.2702e-02, -1.2703e-02,  ..., -1.2701e-02,\n",
       "         -1.2700e-02, -1.2700e-02],\n",
       "        [-5.8073e-03, -5.8065e-03, -5.8051e-03,  ..., -5.8142e-03,\n",
       "         -5.8136e-03, -5.8130e-03],\n",
       "        [ 0.0000e+00,  1.0000e+03,  0.0000e+00,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(dataloader)\n",
    "print('ummm')\n",
    "for i, data in enumerate(pbar):\n",
    "    print(i)\n",
    "    print('hulloooooo')\n",
    "    eeg_array, mel, mel_input, pos_eeg_signal, pos_mel, _ = data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_transformer import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "^^ running succesfully at default settings. no checkpoints (<= fix later)\n",
    "\n",
    "MAIN: shove in eeg data and train and generate sample\n",
    "\n",
    "exp #1: add raw numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2,3,4], [5,6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[::2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "278.85px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
